{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archivematica and Omeka S\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import shutil\n",
    "import glob\n",
    "from pprint import pprint\n",
    "import os\n",
    "import bs4\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from omeka_s_tools2.api import OmekaAPIClient\n",
    "\n",
    "class OmekaClient:\n",
    "  term = \"dcterms:identifier\"\n",
    "\n",
    "  def __init__(self, API_URL, KEY_IDENTITY, KEY_CREDENTIAL):\n",
    "      self.API_URL = API_URL\n",
    "      self.KEY_IDENTITY = KEY_IDENTITY\n",
    "      self.KEY_CREDENTIAL = KEY_CREDENTIAL\n",
    "\n",
    "  def reset(self):\n",
    "      self.omeka_auth = OmekaAPIClient(\n",
    "          api_url=self.API_URL,\n",
    "          key_identity=self.KEY_IDENTITY, \n",
    "          key_credential=self.KEY_CREDENTIAL\n",
    "      )\n",
    "\n",
    "  def check(self):\n",
    "      print(self.API_URL, self.KEY_IDENTITY, self.KEY_CREDENTIAL)\n",
    "\n",
    "  def upload(self, metadata_path, media_path, is_public):\n",
    "      '''アイテムとメディアの登録\n",
    "      '''\n",
    "\n",
    "      self.is_public = is_public\n",
    "\n",
    "      # アイテムの登録\n",
    "      self.upload_items(metadata_path)        \n",
    "\n",
    "      # メディアの登録\n",
    "      items = self.convertCsv2Json(media_path)\n",
    "      self.upload_media(items, media_path)\n",
    "\n",
    "  def upload_items(self, metadata_path):\n",
    "      '''アイテムの登録\n",
    "      '''\n",
    "      print(\"アイテムの登録\")\n",
    "      items = self.convertCsv2Json(metadata_path)\n",
    "      for item in tqdm(items):\n",
    "          self.update(item)\n",
    "\n",
    "  def convertCsv2Json(self, csv_path):\n",
    "      df = pd.read_csv(csv_path)\n",
    "      # print(df)\n",
    "\n",
    "      items = []\n",
    "      for index, row in df.iterrows():\n",
    "          test_item = {}\n",
    "          for column_name, item in df.iteritems():\n",
    "              if column_name not in test_item:\n",
    "                  test_item[column_name] = []\n",
    "              value = row[column_name]\n",
    "              if pd.isnull(value):\n",
    "                  continue\n",
    "              test_item[column_name].append(value)\n",
    "\n",
    "          # pprint(test_item)\n",
    "          items.append(test_item)\n",
    "          # break\n",
    "\n",
    "      # pprint(items)\n",
    "\n",
    "      return items\n",
    "\n",
    "  def getExistingsValues(self, term, value):\n",
    "      url = f\"{self.API_URL}/items?property[0][property]={term}&property[0][type]=eq&property[0][text]={value}&key_identity={self.KEY_IDENTITY}&key_credential={self.KEY_CREDENTIAL}\"\n",
    "      import requests\n",
    "      df = requests.get(url).json()\n",
    "      return df\n",
    "\n",
    "  def update(self, test_item):\n",
    "\n",
    "      term = self.term\n",
    "\n",
    "      self.reset()\n",
    "      omeka_auth = self.omeka_auth\n",
    "\n",
    "      local_item = deepcopy(test_item)\n",
    "\n",
    "      replaced_fields = {}\n",
    "\n",
    "      for field in local_item:\n",
    "          if \"^^resource\" in field:\n",
    "              values = local_item[field]\n",
    "\n",
    "              resources = []\n",
    "\n",
    "              for value in values:\n",
    "                  existing_values = self.getExistingsValues(term, value)\n",
    "\n",
    "                  if len(existing_values) > 0:\n",
    "                      resources.append({\n",
    "                          \"type\": \"resource\",\n",
    "                          \"value\": existing_values[0][\"o:id\"]\n",
    "                      })\n",
    "\n",
    "              '''\n",
    "              del local_item[field]\n",
    "              local_item[field.split(\" \")[0]] = resources\n",
    "              '''\n",
    "              replaced_fields[field] = resources\n",
    "\n",
    "      for field in replaced_fields:\n",
    "          del local_item[field]\n",
    "          local_item[field.split(\" \")[0]] = replaced_fields[field]\n",
    "\n",
    "      payload = omeka_auth.prepare_item_payload(local_item)\n",
    "      \n",
    "      # 既存のIDを取得\n",
    "      id = local_item[term][0]\n",
    "\n",
    "      # 既存のIDを持つアイテムの取得\n",
    "      results = self.getExistingsValues(term, id)\n",
    "\n",
    "      flg = True\n",
    "\n",
    "      if flg:\n",
    "\n",
    "          # 既に存在する場合は更新\n",
    "          if len(results) > 0:\n",
    "              payload_old = results[0]\n",
    "              for key in payload:\n",
    "                  payload_old[key] = payload[key]\n",
    "\n",
    "              payload = payload_old\n",
    "\n",
    "      payload[\"is_public\"] = self.is_public\n",
    "\n",
    "      # バグ修正\n",
    "\n",
    "      for field in payload:\n",
    "          values = payload[field]\n",
    "          if type(values) is not list:\n",
    "              continue\n",
    "          for value in values:\n",
    "              # @value を value_resource_id に置換する\n",
    "              if \"type\" in value and value[\"type\"] == \"resource\" and \"@value\" in value:\n",
    "                  value[\"value_resource_id\"] = value[\"@value\"]\n",
    "\n",
    "      if len(results) > 0:\n",
    "          omeka_auth.update_resource(payload, 'items')\n",
    "      else:\n",
    "          omeka_auth.add_item(payload)\n",
    "\n",
    "  def upload_media(self, items, media_path):\n",
    "      dir = os.path.dirname(media_path)\n",
    "      id_map = {}\n",
    "      term = self.term\n",
    "\n",
    "      print(\"\\nIDの取得\\n\")\n",
    "\n",
    "      for item in tqdm(items):\n",
    "          self.reset()\n",
    "\n",
    "          id = item[\"item\"][0]\n",
    "\n",
    "          if id in id_map:\n",
    "              continue\n",
    "\n",
    "          arr = self.getExistingsValues(term, id)\n",
    "\n",
    "          if len(arr) > 0:\n",
    "              id_map[id] = arr[0][\"o:id\"]\n",
    "\n",
    "      print(\"\\nメディアの登録\\n\")\n",
    "\n",
    "      for item in tqdm(items):\n",
    "          id = item[\"item\"][0]\n",
    "\n",
    "          if id not in id_map:\n",
    "              continue\n",
    "\n",
    "          media_path = f'{dir}/{item[\"path\"][0]}'\n",
    "          oid = id_map[id]\n",
    "\n",
    "          self.reset()\n",
    "          self.omeka_auth.add_media_to_item(oid, media_path)\n",
    "\n",
    "class ArchiveMaticaOmeka:\n",
    "  TMP_DIR_PATH = f\"tmp\"\n",
    "\n",
    "  def __init__(self, dip_zip_file_path, mapping_json_file_path, task_id=\"test\", debug=False):\n",
    "    self.dip_zip_file_path = dip_zip_file_path\n",
    "    mapping_json_file_path = mapping_json_file_path\n",
    "\n",
    "    with open(mapping_json_file_path) as f:\n",
    "      self.mapping = json.load(f)\n",
    "\n",
    "    self.task_id = task_id\n",
    "\n",
    "    tmp_dir_path = f\"{self.TMP_DIR_PATH}/{task_id}\"\n",
    "\n",
    "    self.tmp_dir_path = tmp_dir_path\n",
    "\n",
    "    if os.path.exists(tmp_dir_path):\n",
    "      shutil.rmtree(tmp_dir_path)\n",
    "\n",
    "    self.debug = debug\n",
    "\n",
    "  def unpackArchive(self):\n",
    "    \"\"\"zipファイルの展開\n",
    "    \"\"\"\n",
    "\n",
    "    shutil.unpack_archive(self.dip_zip_file_path, self.tmp_dir_path)\n",
    "\n",
    "  ## \n",
    "  def getMetsFilePath(self):\n",
    "    \"\"\"metsファイルのパスの取得\n",
    "    \"\"\"\n",
    "\n",
    "    files = glob.glob(f\"{self.tmp_dir_path}/*/*.xml\")\n",
    "    # pprint(files)\n",
    "\n",
    "    mets_path = None\n",
    "    for file in files:\n",
    "      if \"METS\" in file:\n",
    "        mets_path = file\n",
    "\n",
    "    # print(mets_path)\n",
    "    self.mets_path = mets_path\n",
    "\n",
    "    # スクレイピング対象のhtmlファイルからsoupを作成\n",
    "    soup = bs4.BeautifulSoup(open(self.mets_path), 'xml')\n",
    "    self.soup = soup\n",
    "\n",
    "    if self.debug:\n",
    "      print(\"-----\\ngetMetsFilePath\\n-----\")\n",
    "      print(soup.prettify())\n",
    "\n",
    "  ## dmdSecの情報の取得\n",
    "  def getDmdSec(self):\n",
    "    \"\"\"dmdSecの情報の取得\n",
    "    \"\"\"\n",
    "    ## metsファイルのパスの取得\n",
    "\n",
    "    mapping = self.mapping\n",
    "\n",
    "    dmdSecs = self.soup.find_all(\"mets:dmdSec\")\n",
    "\n",
    "    items = {}\n",
    "    # 順序を保持するためにlistを使用\n",
    "    item_ids = []\n",
    "    mappings = {}\n",
    "\n",
    "    for dmdSec in dmdSecs:\n",
    "      dmdSec_id = dmdSec.get(\"ID\")\n",
    "      mdWrap = dmdSec.find(\"mets:mdWrap\")\n",
    "      mdType = mdWrap.get(\"MDTYPE\")\n",
    "      # print(mdType)\n",
    "\n",
    "      if mdType == \"DC\":\n",
    "        item = {}\n",
    "        # items.append(item)\n",
    "        dc = mdWrap.find(\"dcterms:dublincore\")\n",
    "        metadata = dc.findChildren()\n",
    "        # pprint(metadata)\n",
    "\n",
    "        for m in metadata:\n",
    "          name = \"dc:\" + m.name\n",
    "          value = m.text\n",
    "          # print(name, value)\n",
    "\n",
    "          if value != \"\" and name in mapping:\n",
    "            p_id = mapping[name]\n",
    "            \n",
    "            # print(\"*\", p_id)\n",
    "\n",
    "            if p_id == \"dcterms:identifier\":\n",
    "              item_ids.append(value)\n",
    "              id = value\n",
    "            else:\n",
    "              item[p_id] = value\n",
    "\n",
    "        items[id] = item\n",
    "\n",
    "        mappings[dmdSec_id] = id\n",
    "\n",
    "      if mdType == \"OTHER\":\n",
    "        # item = {}\n",
    "        # items.append(item)\n",
    "        dc = mdWrap.find(\"mets:xmlData\")\n",
    "        metadata = dc.findChildren()\n",
    "        # pprint(metadata)\n",
    "\n",
    "        for m in metadata:\n",
    "          name = m.name\n",
    "          value = m.text\n",
    "          # print(name, value)\n",
    "\n",
    "          if value != \"\" and name in mapping:\n",
    "            p_id = mapping[name]\n",
    "            \n",
    "            item[p_id] = value\n",
    "\n",
    "        items[id] = item\n",
    "\n",
    "    # pprint(items)\n",
    "\n",
    "    self.items = items\n",
    "    self.item_ids = item_ids\n",
    "    self.dmd_sec_mappings = mappings\n",
    "\n",
    "    if self.debug:\n",
    "      print(\"-----\\nmappings\\ndmdSecとdcterms:identifierの関係\\n-----\")\n",
    "      pprint(mappings)\n",
    "\n",
    "    if self.debug:\n",
    "      print(\"-----\\ngetDmdSec\\ndcterms:identifier毎のメタデータ\\n-----\")\n",
    "      pprint(items)\n",
    "\n",
    "  ## \n",
    "  def getStructMap(self):\n",
    "    \"\"\"structMapの情報の取得\n",
    "    \"\"\"\n",
    "\n",
    "    dmd_sec_mappings = self.dmd_sec_mappings\n",
    "\n",
    "    fptrs = self.soup.find_all(\"mets:fptr\")\n",
    "\n",
    "    structs = []\n",
    "\n",
    "    for fptr in fptrs:\n",
    "      file_id = fptr.get(\"FILEID\")\n",
    "\n",
    "      div_item = fptr.parent\n",
    "\n",
    "      # フラット\n",
    "      if \"DMDID\" in div_item.attrs:\n",
    "        dmd_ids = div_item.get(\"DMDID\").split(\" \")\n",
    "        for dmd_id in dmd_ids:\n",
    "          if dmd_id not in dmd_sec_mappings:\n",
    "            continue\n",
    "\n",
    "          item_id = dmd_sec_mappings[dmd_id]\n",
    "      else:\n",
    "\n",
    "\n",
    "        label_item = div_item.get(\"LABEL\")\n",
    "\n",
    "        div_item_parent = div_item.parent\n",
    "\n",
    "        if label_item in [\"metadata.csv\", \"METS.xml\", \"directory_tree.txt\"]:\n",
    "          continue\n",
    "\n",
    "        item_id = div_item_parent.get(\"LABEL\")\n",
    "\n",
    "        if item_id in [\"OCRfiles\"]:\n",
    "          continue\n",
    "\n",
    "      structs.append({\n",
    "        \"file\": file_id,\n",
    "        \"item_id\": item_id  # label_item_parent # label_item\n",
    "      })\n",
    "\n",
    "    hie = {}\n",
    "\n",
    "    oDiv = self.soup.find(\"mets:div\", {\"LABEL\": \"objects\"})\n",
    "\n",
    "    for div in oDiv.find_all(\"mets:div\"):\n",
    "      label = div.get(\"LABEL\")\n",
    "      parent = div.parent\n",
    "      pid = parent.get(\"LABEL\")\n",
    "      hie[label] = pid\n",
    "\n",
    "    self.structs = structs\n",
    "\n",
    "    self.hie = hie\n",
    "\n",
    "    if self.debug:\n",
    "      print(\"-----\\nstructs\\n-----\")\n",
    "      pprint(structs)\n",
    "\n",
    "    if self.debug:\n",
    "      print(\"-----\\nhie\\n-----\")\n",
    "      pprint(hie)\n",
    "\n",
    "  def getFileSec(self):\n",
    "    \"\"\"fileSecの情報の取得\n",
    "    \"\"\"\n",
    "\n",
    "    ## mets:fileGrpの情報の取得\n",
    "\n",
    "    fileSec = self.soup.find_all(\"mets:fileGrp\")[0]\n",
    "\n",
    "    files = fileSec.find_all(\"mets:file\")\n",
    "\n",
    "    file_map = {}\n",
    "\n",
    "    for file in files:\n",
    "      file_id = file.get(\"ID\")\n",
    "      # print(file_id)\n",
    "      flocat = file.find(\"mets:FLocat\").get(\"xlink:href\")\n",
    "      # print(flocat)\n",
    "      file_map[file_id] = flocat\n",
    "\n",
    "    if self.debug:\n",
    "      print(\"-----\\nfile_map\\n-----\")\n",
    "      pprint(file_map)\n",
    "\n",
    "    self.file_map = file_map\n",
    "\n",
    "  def createOmeka(self):\n",
    "    \"\"\"Omekaへの登録用のフォーマットに変換\n",
    "    \"\"\"\n",
    "    ## \n",
    "\n",
    "    file_map = self.file_map\n",
    "    structs = self.structs\n",
    "    items = self.items\n",
    "    tmp_dir_path = self.tmp_dir_path\n",
    "\n",
    "    hie = self.hie\n",
    "\n",
    "    ###\n",
    "\n",
    "    # params = []\n",
    "    # rows = []\n",
    "    # id_exists = []\n",
    "\n",
    "    # メディア\n",
    "\n",
    "    medias = []\n",
    "\n",
    "    for struct in structs:\n",
    "\n",
    "      # struct: 構造情報を持つ\n",
    "\n",
    "      item_id = struct[\"item_id\"]\n",
    "\n",
    "      if \"file\" in struct:\n",
    "\n",
    "        file_id = struct[\"file\"]\n",
    "\n",
    "        # print(file_id, file_id in file_map)\n",
    "\n",
    "        if file_id not in file_map:\n",
    "          continue\n",
    "\n",
    "        path = \"objects/\" +  file_id.replace(\"file-\", \"\") + \"-\" + file_map[file_id].split(\"/\")[-1]\n",
    "\n",
    "        medias.append({\n",
    "            \"item\": item_id, # id,\n",
    "            \"path\": path\n",
    "        })\n",
    "\n",
    "    item_ids = self.item_ids\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # from copy import deepcopy\n",
    "\n",
    "    for item_id in item_ids:\n",
    "      row = items[item_id]\n",
    "      row[\"dcterms:identifier\"] = item_id\n",
    "      if item_id in hie:\n",
    "        row[\"dcterms:isPartOf ^^resource\"] = hie[item_id]\n",
    "      rows.append(row)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    df = json_normalize(rows)\n",
    "\n",
    "    df.to_csv(f'{tmp_dir_path}/metadata.csv', index=False)\n",
    "\n",
    "    \n",
    "    df_m = json_normalize(medias)\n",
    "    df_m\n",
    "\n",
    "    # print(df_m)\n",
    "\n",
    "    df_m.to_csv(f'{tmp_dir_path}/media.csv', index=False)\n",
    "\n",
    "  \n",
    "  def moveObjects(self):\n",
    "    \"\"\"Omekaへの登録用のフォーマットに変換\n",
    "    \"\"\"\n",
    "    ## \n",
    "    path = glob.glob(f\"{self.tmp_dir_path}/*/objects\")[0]\n",
    "    shutil.move(path, f\"{self.tmp_dir_path}\")\n",
    "\n",
    "  @staticmethod\n",
    "  def convert(dip_zip_file_path, mapping_json_file_path, task_id=\"bcd\"):\n",
    "    \"\"\"Omekaへの登録用のフォーマットに変換\n",
    "\n",
    "    Parameters:\n",
    "    * `dip_zip_file_path` - path to a dip zip file exported from Archivematica (str or pathlib Path)  \n",
    "    * `mapping_json_file_path` - path to a mappin file between Archivematica and Omeka (str or pathlib Path)  \n",
    "    * `task_id` - (Optional) Task ID (str)\n",
    "    \"\"\"\n",
    "    archiveMaticaOmeka = ArchiveMaticaOmeka(dip_zip_file_path, mapping_json_file_path,task_id, debug=False)\n",
    "    archiveMaticaOmeka.unpackArchive()\n",
    "    archiveMaticaOmeka.getMetsFilePath()\n",
    "    \n",
    "    # print(\"a\", \"b\")\n",
    "    \n",
    "    archiveMaticaOmeka.getDmdSec()\n",
    "    archiveMaticaOmeka.getStructMap()\n",
    "    archiveMaticaOmeka.getFileSec()\n",
    "    archiveMaticaOmeka.createOmeka()\n",
    "    archiveMaticaOmeka.moveObjects()\n",
    "\n",
    "\n",
    "    return archiveMaticaOmeka.tmp_dir_path\n",
    "\n",
    "  @staticmethod\n",
    "  def upload(metadata_csv_path, media_csv_path, API_URL, KEY_IDENTITY, KEY_CREDENTIAL, is_public=True):\n",
    "    client = OmekaClient(API_URL, KEY_IDENTITY, KEY_CREDENTIAL)\n",
    "    client.upload(metadata_csv_path, media_csv_path, is_public=is_public)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### ArchiveMaticaOmeka.convert\n",
       "\n",
       ">      ArchiveMaticaOmeka.convert (dip_zip_file_path, mapping_json_file_path,\n",
       ">                                  task_id='bcd')\n",
       "\n",
       "Omekaへの登録用のフォーマットに変換\n",
       "\n",
       "Parameters:\n",
       "* `dip_zip_file_path` - path to a dip zip file exported from Archivematica (str or pathlib Path)  \n",
       "* `mapping_json_file_path` - path to a mappin file between Archivematica and Omeka (str or pathlib Path)  \n",
       "* `task_id` - (Optional) Task ID (str)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### ArchiveMaticaOmeka.convert\n",
       "\n",
       ">      ArchiveMaticaOmeka.convert (dip_zip_file_path, mapping_json_file_path,\n",
       ">                                  task_id='bcd')\n",
       "\n",
       "Omekaへの登録用のフォーマットに変換\n",
       "\n",
       "Parameters:\n",
       "* `dip_zip_file_path` - path to a dip zip file exported from Archivematica (str or pathlib Path)  \n",
       "* `mapping_json_file_path` - path to a mappin file between Archivematica and Omeka (str or pathlib Path)  \n",
       "* `task_id` - (Optional) Task ID (str)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ArchiveMaticaOmeka.convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dip_zip_file_path = \"data/sample/ex02-1-TIFF-007c28cc-4671-4d5d-be2a-facace4c7b84.zip\"\n",
    "mapping_json_file_path=\"data/sample/mapping.json\"\n",
    "output_dir = ArchiveMaticaOmeka.convert(dip_zip_file_path, mapping_json_file_path, task_id=\"bcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### ArchiveMaticaOmeka.upload\n",
       "\n",
       ">      ArchiveMaticaOmeka.upload (metadata_csv_path, media_csv_path, API_URL,\n",
       ">                                 KEY_IDENTITY, KEY_CREDENTIAL, is_public=True)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### ArchiveMaticaOmeka.upload\n",
       "\n",
       ">      ArchiveMaticaOmeka.upload (metadata_csv_path, media_csv_path, API_URL,\n",
       ">                                 KEY_IDENTITY, KEY_CREDENTIAL, is_public=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ArchiveMaticaOmeka.upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = os.getenv(\"API_URL\")\n",
    "KEY_IDENTITY = os.getenv(\"KEY_IDENTITY\")\n",
    "KEY_CREDENTIAL = os.getenv(\"KEY_CREDENTIAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アイテムの登録\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:25<00:00,  6.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IDの取得\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "メディアの登録\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:34<00:00,  8.66s/it]\n"
     ]
    }
   ],
   "source": [
    "metadata_csv_path = f\"{output_dir}/metadata.csv\"\n",
    "media_csv_path = f\"{output_dir}/media.csv\"\n",
    "ArchiveMaticaOmeka.upload(metadata_csv_path, media_csv_path, API_URL, KEY_IDENTITY, KEY_CREDENTIAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 11)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/nakamura/python-microscopy/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3457\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"/var/folders/z5/3p9s8m011dv0tjt7ch21jtmh0000gn/T/ipykernel_6002/1049215.py\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    import nbdev; nbdev.nbdev_export()\n",
      "  File \u001b[1;32m\"/Users/nakamura/python-microscopy/lib/python3.7/site-packages/fastcore/script.py\"\u001b[0m, line \u001b[1;32m110\u001b[0m, in \u001b[1;35m_f\u001b[0m\n    if not mod: return func(*args, **kwargs)\n",
      "  File \u001b[1;32m\"/Users/nakamura/python-microscopy/lib/python3.7/site-packages/nbdev/doclinks.py\"\u001b[0m, line \u001b[1;32m135\u001b[0m, in \u001b[1;35mnbdev_export\u001b[0m\n    _build_modidx()\n",
      "  File \u001b[1;32m\"/Users/nakamura/python-microscopy/lib/python3.7/site-packages/nbdev/doclinks.py\"\u001b[0m, line \u001b[1;32m97\u001b[0m, in \u001b[1;35m_build_modidx\u001b[0m\n    res['syms'].update(_get_modidx((dest.parent/file).resolve(), code_root, nbs_path=nbs_path))\n",
      "  File \u001b[1;32m\"/Users/nakamura/python-microscopy/lib/python3.7/site-packages/nbdev/doclinks.py\"\u001b[0m, line \u001b[1;32m75\u001b[0m, in \u001b[1;35m_get_modidx\u001b[0m\n    for tree in ast.parse(cell.code).body:\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/nakamura/python-microscopy/lib/python3.7/ast.py\"\u001b[0;36m, line \u001b[0;32m35\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, PyCF_ONLY_AST)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    %load_ext dotenv\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
